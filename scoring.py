import os
import datetime
import json
import numpy as np
import pandas as pd
import gc

from model.subflows.drgnet.score import drgnet_predict
from model.subflows.drgnet2.score import drgnet2_predict
from model.subflows.selfcure.score import selfcure_predict
from model.subflows.earlylate.score import earlylate_predict
from model.utils import mlog, OUTPUT_COLLS


def common_preprocess(df_src: pd.DataFrame) -> pd.DataFrame:
    """
    df_src: исходные данные, полученные из input_table
    Приведение полей+ общие преобразования
    """
    df = df_src.copy()

    # переименование полей
    with open('model/colmapping.json', 'rb') as f:
        colmap = json.load(f)
        df.rename(columns=colmap, inplace=True)

    # Определяем сегмент
    df['segment'] = np.nan
    df.loc[(df.curr_delinq_mortgage_dbt > 0) & (df.curr_delinq_mortgage_dbt < 999_999_999), 'segment'] = 'mortgage'
    df.loc[((df.curr_delinq_consumer_dbt > 0) & (df.curr_delinq_consumer_dbt < 999_999_999) |
            (df.curr_delinq_auto_dbt > 0) & (df.curr_delinq_auto_dbt < 999_999_999)) &
            (df.segment.isna()), 'segment'] = 'customer'
    df.segment.fillna('card', inplace=True)

    if df['assd_client_id'].isnull().any():
        mlog("assd_client_id contains nulls, cannot proceed")
        raise AttributeError("assd_client_id contains nulls")

    # общие приведения типов/полей
    df['cust_epk_sid'] = df['assd_client_id'].values
    df['cust_epk_sid'] = df['cust_epk_sid'].astype(str)
    df['assd_client_id'] = df['assd_client_id'].astype(str)
    df['report_date'] = pd.to_datetime(df['report_date'], errors='coerce')
    df['record_type'] = pd.to_numeric(df['record_type'], errors='coerce')

    return df


def common_post_preprocess(df_out: pd.DataFrame) -> pd.DataFrame:
    """
    df_out: датафрейм с выходными данными
    Приведение полей + общие преобразования
    """
    df = df_out[OUTPUT_COLLS].copy()

    # float fields to str
    df['predict_model_before_calibr_val'] = [f'{v:0.18f}' if not pd.isnull(v) else ""
                                             for v in df['predict_model_before_calibr_val'].astype(float)]
    df['predict_model_before_calibr_val'] = df['predict_model_before_calibr_val'].astype(str)

    # str int fields
    str_fields = [
        'comm_hard_type_code',
        'model_colln_sys_sid',
        'model_library_sid',
    ]

    def try_cast_to_int_str(val):
        try:
            return str(int(val))
        except:
            return ""

    for f in str_fields:
        df[f] = [try_cast_to_int_str(v) if not pd.isnull(v) else "" for v in df[f]]
        df[f] = df[f].astype(str)

    return df


def process_data(df_src: pd.DataFrame, df_opti_step1: pd.DataFrame) -> pd.DataFrame:
    """
    Полный расчет (на вход поля ПКАП)
    df_src: исходные данные, полученные из input_table
    df_opti_step1: справочник criterion-cut-off
    """
    assert df_src is not None
    assert df_opti_step1 is not None
    t0 = datetime.datetime.now()

    try:
        #
        # ----------------------- приводим к полям + общие преобразования -------------------------
        df_map = common_preprocess(df_src)
        t1 = datetime.datetime.now()
        mlog(f't0: df_src.shape={df_src.shape}')
        mlog(f't0: df_map.shape={df_map.shape}')
        mlog('----------------------------------\n')

        #
        # -------------------------------- получаем расчет dragonnet -----------------------------------
        # для клиентов 43 группы -- dragonnet с фиксированным таргетом
        df_drg_43 = drgnet_predict(df_map[df_map['ch_ch_group_id'] == 43].copy())
        mlog(f't2: df_drg_43.shape={df_drg_43.shape}')
        mlog('-----------------\n')

        # для клиентов 42 группы -- dragonnet с плавающим таргетом
        df_drg_42 = drgnet2_predict(df_map[df_map['ch_ch_group_id'] == 42].copy(), df_opti_step1)
        mlog(f't2: df_drg_42.shape={df_drg_42.shape}')
        mlog('-----------------\n')

        # объединяем
        df_drg = pd.concat([df_drg_42, df_drg_43]).reset_index(drop=True)

        t2 = datetime.datetime.now()
        mlog(f't2: df_drg.shape={df_drg.shape}')
        mlog('----------------------------------\n')

        #
        # ------------------------- добавялем к dragonnet расчет selfcure -----------------------------
        df_selfcure = selfcure_predict(df_map, df_drg, df_opti_step1)
        # теперь в df_selfcure: selfcure+dragonnet
        t3 = datetime.datetime.now()
        mlog(f't3: df_selfcure.shape={df_selfcure.shape}')
        mlog('----------------------------------\n')

        #
        # ------------------- добавялем к dragonnet и selfcure расчет earlylate -----------------------
        df_earlylate = earlylate_predict(df_map, df_selfcure, df_opti_step1)
        # теперь в df_earlylate: selfcure+dragonnet+earlylate
        t4 = datetime.datetime.now()
        mlog(f't4: df_earlylate.shape={df_earlylate.shape}')
        mlog('----------------------------------\n')

        #
        # -------------------------------- финальные преобразования -----------------------------------
        df_final = common_post_preprocess(df_earlylate)
        t5 = datetime.datetime.now()
        mlog(f't5: df_final.shape={df_final.shape}')
        mlog('----------------------------------\n')

        #
        # ----------------------------------- total stats ---------------------------------------------
        t_data_preprocess = (t1 - t0).total_seconds()
        t_drgnet_predict = (t2 - t1).total_seconds()
        t_selfcure_predict = (t3 - t2).total_seconds()
        t_earlylate_predict = (t4 - t3).total_seconds()
        t_post_preprocess = (t5 - t4).total_seconds()

        mlog(f't_data_preprocess:   {t_data_preprocess:0.2f}s')
        mlog(f't_drgnet_predict:    {t_drgnet_predict:0.2f}s')
        mlog(f't_selfcure_predict:  {t_selfcure_predict:0.2f}s')
        mlog(f't_earlylate_predict: {t_earlylate_predict:0.2f}s')
        mlog(f't_post_preprocess:   {t_post_preprocess:0.2f}s')

    except Exception as e:
        mlog(f'EXCEPTION: {e}')

        if len(df_src) > 0:
            if 'cust_sid' in df_src.columns and 'vector_neuro_model_rec_num' in df_src.columns:
                mlog(f'failed on the next cust_sids:')
                df_src['cnt'] = 1
                df_gr = df_src.groupby(by=['cust_sid', 'vector_neuro_model_rec_num'])['cnt'].sum().reset_index()
                for idx, row in df_gr.iterrows():
                    mlog(f'cust_sid={row["cust_sid"]}, vec_num={row["vector_neuro_model_rec_num"]}, cnt={row["cnt"]}')

        raise e

    finally:
        tf = datetime.datetime.now()
        t_total = (tf - t0).total_seconds()
        mlog(f't_total: {t_total:0.2f}s')
        gc.collect()

    if os.environ.get('DEBUG_BREAKE_DRG') == 'BREAK':
        raise NotImplementedError('DEBUG_BREAKE_DRG')

    return df_final
